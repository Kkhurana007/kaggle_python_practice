{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1656a7f1-fdb4-4a6b-9ecc-3413dfb8a24e",
   "metadata": {},
   "source": [
    "# Approcahes to deal with missing values\n",
    "> 1. `Drop column`\n",
    "\n",
    "> 2. `Imputation`\n",
    "\n",
    "> 3. `Extension to Imputation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "740b63c3-2d8c-473d-8576-7440f8055335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example usage\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load data\n",
    "data = pd.read_csv('melb_data.csv')\n",
    "\n",
    "# select target\n",
    "y = data.Price\n",
    "\n",
    "# numerical predicators\n",
    "melb_predictors = data.drop(['Price'], axis = 1) \n",
    "X = melb_predictors.select_dtypes(exclude=['object'])\n",
    "\n",
    "# divide it into training and validation subsets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size = 0.8, \n",
    "                                                      test_size = 0.2, \n",
    "                                                      random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba8f88ae-99e4-41c0-8a89-b731c87f9650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# function to compare diff approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7956db-e535-4f9e-b6de-0714c630ee61",
   "metadata": {},
   "source": [
    "### Score from approach_1- `Drop column`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a180111-3978-4830-8462-9a8e3149d29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approch_1 (after having dropped the column values): \n",
      "183550.22137772635\n"
     ]
    }
   ],
   "source": [
    "# get names of missing columns\n",
    "cols_missing = [col for col in X_train.columns\n",
    "                if X_train[col].isnull().any()]\n",
    "\n",
    "# drop them\n",
    "reduced_X_train = X_train.drop(cols_missing, axis = 1)\n",
    "reduced_X_valid = X_valid.drop(cols_missing, axis = 1)\n",
    "\n",
    "print(\"MAE from Approch_1 (after having dropped the column values): \")\n",
    "print(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6b2416-346d-4f4e-b96a-d799594c0833",
   "metadata": {},
   "source": [
    "### Score from appraoch_2- `Imputation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f02d98b5-9a5e-4bbe-a8a2-080270dfc725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 2 (imputation):\n",
      "178166.46269899711\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# imputation\n",
    "my_imputer = SimpleImputer()\n",
    "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
    "\n",
    "# imputation removed\n",
    "imputed_X_train.columns = X_train.columns\n",
    "imputed_X_valid.columns = X_valid.columns\n",
    "\n",
    "print(\"MAE from Approach 2 (imputation):\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))\n",
    "\n",
    "                               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35083afa-324a-4013-9272-dac7e059ad5d",
   "metadata": {},
   "source": [
    "### Score from approach_3 - `Extension to imputation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2d26c68-f4e4-4c84-a9cd-091caee18841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 3 (an extension to imputation):\n",
      "178927.503183954\n"
     ]
    }
   ],
   "source": [
    "# make a copy\n",
    "X_train_plus = X_train.copy()\n",
    "X_valid_plus = X_valid.copy()\n",
    "\n",
    "# make new columns indicating what will be imputed\n",
    "for col in cols_missing:\n",
    "    X_train_plus[col + 'was_missing']= X_train_plus[col].isnull()\n",
    "    X_valid_plus[col + 'was_missing'] = X_valid_plus[col].isnull()\n",
    "\n",
    "# imputation\n",
    "my_imputer = SimpleImputer()\n",
    "imputed_X_train_plus = pd.DataFrame(my_imputer.fit_transform(X_train_plus))\n",
    "imputed_X_valid_plus = pd.DataFrame(my_imputer.transform(X_valid_plus))\n",
    "\n",
    "# imputation removed column names: put them back\n",
    "imputed_X_train_plus.columns = X_train_plus.columns\n",
    "imputed_X_valid_plus.columns = X_valid_plus.columns\n",
    "\n",
    "print(\"MAE from Approach 3 (an extension to imputation):\")\n",
    "print(score_dataset(imputed_X_train_plus, imputed_X_valid_plus, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5815bc80-6a77-4a7e-b4c7-88884f8bbde6",
   "metadata": {},
   "source": [
    "### Inference\n",
    "`Imputaion` performs better than dropping the columns because dropping removed lot of useful information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3578ac95-0d8a-47a0-8ba4-f95d32851753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10864, 12)\n",
      "Car               49\n",
      "BuildingArea    5156\n",
      "YearBuilt       4307\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# shape of data\n",
    "print(X_train.shape)\n",
    "\n",
    "# number of missing values\n",
    "missing_val_count_by_column = (X_train.isnull().sum())\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab43003-4d33-4029-82bd-8986e4d4ad38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
